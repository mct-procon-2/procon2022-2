{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb258d-a37b-493b-9eaf-d3911dd3aa67",
   "metadata": {
    "id": "c5bb258d-a37b-493b-9eaf-d3911dd3aa67"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import write\n",
    "import soundfile as sf\n",
    "import random\n",
    "import os, sys\n",
    "import subprocess\n",
    "#subprocess.run(\"pip install pydub\", shell = True)\n",
    "import pydub\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3746fa-1310-469f-9c76-d8656cc29501",
   "metadata": {
    "id": "3b3746fa-1310-469f-9c76-d8656cc29501"
   },
   "outputs": [],
   "source": [
    "# 問題作成ツール\n",
    "# 無音wavファイル: http://hitotose-switch.blogspot.com/2013/12/wav.html\n",
    "class Question:\n",
    "    SR = 48000 # サンプリング周波数\n",
    "    \n",
    "    # サンプリング値を秒に変換\n",
    "    # こちらはサンプリング値でずらしたいが、Pydubは秒を欲しがる\n",
    "    def rate2sec(rate):\n",
    "        return rate / Question.SR\n",
    "    \n",
    "    # カット 頭と末尾のデータを刈り取る\n",
    "    # 頭と末尾何秒「切り取るか?」を指定\n",
    "    def cut_wave(x, head=0, tail=0):\n",
    "        head = Question.rate2sec(head) * 1000\n",
    "        tail = Question.rate2sec(tail) * 1000\n",
    "        x = x[head:x.duration_seconds * 1000 - tail]\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    # 2つの波形を合成する(ループで呼び出して複数まぜる、全ての波形を合成)\n",
    "    # カットをしてからここを呼び出す\n",
    "    def mix_wave(mix, x, skip=0):\n",
    "        skip = Question.rate2sec(skip)\n",
    "        mix  = mix.overlay(x, skip * 1000)\n",
    "        return mix\n",
    "    \n",
    "    # 128個の問題データを作る\n",
    "    # \"wave_file/\"ディレクトリに作成します。ディレクトリを作っておいてください。\n",
    "    # \"muon_10.sec.wav\"はカレントディレクトリに\n",
    "    # サンプルデータは\"JKspeech/\"から引っ張ります\n",
    "    def create(w):\n",
    "        for lp in range(0, 128):\n",
    "            print(lp)\n",
    "            # 無音データ(重ね合わせ用)\n",
    "            muon = AudioSegment.from_file(\"muon_10sec.wav\", format=\"wav\")\n",
    "            muon = muon + muon + muon; #30秒の無音データ\n",
    "            # 作成\n",
    "            speech = np.empty(0) # 読みデータ\n",
    "            offset = np.empty(0) # 開始位置\n",
    "            mix = muon\n",
    "            max_time = 0\n",
    "            num = random.randint(2, 20)\n",
    "            remain = np.empty(0)\n",
    "            ej = [\"E\", \"J\"]\n",
    "            for i in range(1, 45):\n",
    "                remain = np.append(remain, str(i).zfill(2))\n",
    "            \n",
    "            #print(\"合成数: \" + str(num))\n",
    "            for i in range(0, num):\n",
    "                r_mus = random.randint(0, remain.size - 1)\n",
    "                r_ej = random.randint(0, 1)\n",
    "                #path = \"/content/drive/MyDrive/JKspeech/\" + ej[r_ej] + remain[r_mus] + \".wav\" #勝手に変えました(content/drive)\n",
    "                path = \"JKspeech/\" + ej[r_ej] + remain[r_mus] + \".wav\"\n",
    "                speech = np.append(speech, ej[r_ej] + remain[r_mus])\n",
    "                #print(path)\n",
    "                base_sound = AudioSegment.from_file(path, format=\"wav\")\n",
    "                #print(\"初期状態:\" + str(base_sound.duration_seconds) + \"秒\") # カット前の秒数\n",
    "                head_cut = random.randint(0, int(48000 * base_sound.duration_seconds - 24000)) # 0.5s以上確実に残して頭からカット\n",
    "                tail_cut = random.randint(0, int(48000 * base_sound.duration_seconds - head_cut - 24000)) # 0.5s以上確実に残して後ろからカット\n",
    "                base_sound = Question.cut_wave(base_sound, head = head_cut, tail = tail_cut)\n",
    "                #print(\"最終状態:\" + str(base_sound.duration_seconds) + \"秒\") # カット後の秒数\n",
    "                skip_time = random.randint(0, max_time) #飛ばす時間\n",
    "                offset = np.append(offset, skip_time)\n",
    "                #print(\"スキップ時間:\" + str(Question.rate2sec(skip_time)) + \"秒\")\n",
    "                max_time = max(max_time, skip_time + int(base_sound.duration_seconds * Question.SR))\n",
    "                #print(\"合計時間:\" + str(Question.rate2sec(max_time)) + \"秒\")\n",
    "                mix = Question.mix_wave(mix, base_sound, skip=skip_time) # 周波数単位でずらす\n",
    "                remain = np.delete(remain, r_mus)\n",
    "            \n",
    "            outfile_name = \"wave_file/information\" + str(lp) + \".txt\"\n",
    "            f = open(outfile_name, mode='w')\n",
    "            f.write(\"nspeech: \" + str(num) + \"\\n\")\n",
    "            \n",
    "            s = \"speech: \"\n",
    "            for i in range(0, num):\n",
    "                s += str(speech[i])\n",
    "                if (i != num - 1):\n",
    "                    s += \", \"\n",
    "            f.write(s)\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            s = \"offset: \"\n",
    "            for i in range(0, num):\n",
    "                s += str(int(offset[i]))\n",
    "                if (i != num - 1):\n",
    "                    s += \", \"\n",
    "            f.write(s)\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            f.close()\n",
    "            \n",
    "            #print(\"最終時間\" + str(Question.rate2sec(max_time)) + \"秒\")\n",
    "            mix = mix[:int(Question.rate2sec(max_time) * 1000)]\n",
    "            outfile_name = \"wave_file/mix\" + str(lp) + \".wav\"\n",
    "            mix.export(outfile_name, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49902487-c1a4-4263-aa13-7c03052f10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習モデル\n",
    "def conv1x5(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv1d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size = 5,\n",
    "        stride = stride,\n",
    "        padding = 2,\n",
    "        bias = False\n",
    "    )\n",
    "\n",
    "def conv1x1(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv1d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size = 1,\n",
    "        stride = stride,\n",
    "        bias = False\n",
    "    )\n",
    "\n",
    "#ResNet34以下で使うやつ\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, begin_channels, stride = 1):\n",
    "        super().__init__()\n",
    "        end_channels = begin_channels * self.expansion\n",
    "        self.conv1 = conv1x5(in_channels, begin_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(begin_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv1x5(begin_channels, end_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(end_channels)\n",
    "        \n",
    "        #入力と出力のチャネル数が異なるとき、ダウンサンプリングする\n",
    "        if in_channels != end_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                conv1x1(in_channels, end_channels, stride),\n",
    "                nn.BatchNorm1d(end_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.bn1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.bn2(y)\n",
    "        \n",
    "        y += self.shortcut(x)\n",
    "        \n",
    "        y = self.relu(y)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "#Resnet50以上で使うやつ\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, begin_channels, stride=1):\n",
    "        super().__init__()\n",
    "        end_channels = begin_channels * self.expansion\n",
    "        self.conv1 = conv1x1(in_channels, begin_channels)\n",
    "        self.bn1 = nn.BatchNorm1d(begin_channels)\n",
    "        self.conv2 = conv1x5(begin_channels,begin_channels,stride)\n",
    "        self.bn2 = nn.BatchNorm1d(begin_channels)\n",
    "        self.conv3 = conv1x1(begin_channels, end_channels)\n",
    "        self.bn3 = nn.BatchNorm1d(end_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        #入出力のチャネル数が違えばダウンサンプリング（同じとき無くないか？）\n",
    "        if in_channels != end_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                conv1x1(in_channels, end_channels, stride),\n",
    "                nn.BatchNorm1d(end_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.bn1(y)\n",
    "        y = self.relu(y)\n",
    "        \n",
    "        y = self.conv2(y)\n",
    "        y = self.bn2(y)\n",
    "        y = self.relu(y)\n",
    "        \n",
    "        y = self.conv3(y)\n",
    "        y = self.bn3(y)\n",
    "        \n",
    "        y += self.shortcut(x)\n",
    "        \n",
    "        y = self.relu(y)\n",
    "        \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703fc15-5734-4d73-a89c-444bf4dd7a5e",
   "metadata": {
    "id": "c703fc15-5734-4d73-a89c-444bf4dd7a5e"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        #24000->8000->2000->500->125->32->1\n",
    "        #(st) 4->4->4->4->4\n",
    "        #(pad) 12->2->2->2->2\n",
    "        #(ker) 25->5->5->5->5\n",
    "        self.out_channels = 64\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels = 1,\n",
    "            out_channels = self.out_channels,\n",
    "            kernel_size = 25,\n",
    "            stride = 4,\n",
    "            padding = 12,\n",
    "            bias = False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm1d(self.out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=5,stride=2,padding=2)\n",
    "        self.conv2 = self._make_layer(block,64,layers[0],stride = 4)\n",
    "        self.conv3 = self._make_layer(block,128,layers[1],stride = 4)\n",
    "        self.conv4 = self._make_layer(block,256,layers[2],stride = 4)\n",
    "        self.conv5 = self._make_layer(block,512,layers[3],stride = 4)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode = \"fan_out\", nonlinearity = \"relu\")\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def _make_layer(self, block, channels, blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.out_channels, channels, stride))\n",
    "        self.out_channels = channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.out_channels, channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        #x = nn.Softmax(dim=1)(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d4d000-2c2e-4e88-a652-85335959c142",
   "metadata": {
    "id": "09d4d000-2c2e-4e88-a652-85335959c142"
   },
   "outputs": [],
   "source": [
    "def resnet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "def resnet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "def resnet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "def resnet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef997a0d-27db-4fc6-8a22-e6006b3b35d8",
   "metadata": {
    "id": "ef997a0d-27db-4fc6-8a22-e6006b3b35d8"
   },
   "outputs": [],
   "source": [
    "model = resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090606ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "090606ed",
    "outputId": "5c30e3aa-76c4-4a0b-c836-7bc3c8aa130d"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36a8f6",
   "metadata": {
    "id": "3a36a8f6"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838ae10e-09dc-4023-aa1c-9e65edde5978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習に使うメソッド\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZZ71ERUJuRQZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZZ71ERUJuRQZ",
    "outputId": "2078c3ce-742f-47de-d682-4b424fba0cf3",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 問題作成\n",
    "question = Question()\n",
    "question.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371762f-dc96-442f-ab41-ed6de484ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#波形データを得る\n",
    "file_path = \"wave_file/\"\n",
    "wave_name = np.array([\"mix\" + str(i) + \".wav\" for i in range(0, 128)])\n",
    "\n",
    "#波形の長さが異なるのでどうにかしないといけない\n",
    "#学習では0.5秒に切り抜く（ランダムに）\n",
    "#本番はそのままの音声を受け取ってCNNに入れるときに分割する\n",
    "X = np.empty(0)\n",
    "FS = np.empty(0)\n",
    "for name in wave_name:\n",
    "    x, fs = librosa.load(file_path + name, sr=48000)\n",
    "    rstart = random.randint(0, len(x)-24000)\n",
    "    X = np.append(X, x[rstart:rstart+24000])\n",
    "    FS = np.append(FS, fs)\n",
    "X = X.reshape([-1,24000])\n",
    "#print(X)\n",
    "#print(FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5172f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "1a5172f2",
    "outputId": "2a018f86-38cc-452e-a670-81b7cc780dc5",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#各モデルに対して学習\n",
    "Target = [] # E01からJ44を作成\n",
    "EJ = [\"E\", \"J\"]\n",
    "for ej in EJ:\n",
    "    for i in range(1, 45):\n",
    "        Target.append(ej + str(i).zfill(2))\n",
    "\n",
    "for target in Target:\n",
    "    #モデルの読み込み\n",
    "    #モデルを一度保存してないとエラーします（とりあえずはここのコード無視してね）\n",
    "    #GPU\n",
    "    if torch.cuda.is_available():\n",
    "        model_path = 'model/model_' + target + '.pth'\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    #CPU\n",
    "    else:\n",
    "        model_path = 'model/model_cpu_' + target + '.pth'\n",
    "        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    \n",
    "    #狙いの音声が使われているかを取る\n",
    "    file_path = \"wave_file/\"\n",
    "    label_name = np.array([\"information\" + str(i) + \".txt\" for i in range(0,128)])\n",
    "    \n",
    "    Y = np.empty(0)\n",
    "    for name in label_name:\n",
    "        f = open(file_path + name, 'r')\n",
    "        s = f.read()\n",
    "        #答えは[無い率,有る率]とする\n",
    "        if target in s:\n",
    "            Y = np.append(Y, 1)\n",
    "        else:\n",
    "            Y = np.append(Y, 0)\n",
    "    #Y = Y.reshape([-1,1])\n",
    "    #print(Y)\n",
    "    \n",
    "    #データセット作成\n",
    "    #参考：https://dreamer-uma.com/pytorch-dataset/\n",
    "    tensorX = torch.tensor(X, dtype=torch.float32)\n",
    "    tensorY = torch.tensor(Y, dtype=torch.int64)\n",
    "    Dataset = torch.utils.data.TensorDataset(tensorX, tensorY)\n",
    "    \n",
    "    #データローダー作成\n",
    "    trainloader = torch.utils.data.DataLoader(dataset=Dataset,\n",
    "                                              batch_size = 32,\n",
    "                                              shuffle = True,\n",
    "                                              num_workers = 0)\n",
    "    \n",
    "    #学習\n",
    "    #参考 https://qiita.com/mathlive/items/8e1f9a8467fff8dfd03c\n",
    "    train_loss_value = []\n",
    "    train_acc_value = []\n",
    "    #test_loss_value = []\n",
    "    #test_acc_value = []\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    EPOCH = 3\n",
    "    for epoch in range(EPOCH):\n",
    "        print('epoch', epoch+1)\n",
    "        sum_loss = 0.0\n",
    "        sum_correct = 0\n",
    "        sum_total = 0\n",
    "        for (inputs, labels) in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            #inputsの大きさが24000(0.5秒)じゃないとダメ\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            #print(inputs.shape)\n",
    "            outputs = model(inputs)\n",
    "            print(outputs[0])\n",
    "            print(labels[0])\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            sum_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)  #出力の最大値の添え字を取得\n",
    "            sum_total += labels.size(0)  #labelの数を足していくことでデータの総和を得る\n",
    "            sum_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        mean_loss = sum_loss*BATCH_SIZE/len(trainloader.dataset)\n",
    "        mean_accuracy = float(sum_correct/sum_total)\n",
    "        print(\"train mean loss={}, accuracy={}\".format(mean_loss, mean_accuracy))\n",
    "        train_loss_value.append(mean_loss)\n",
    "        train_acc_value.append(mean_accuracy)\n",
    "        \"\"\"\n",
    "        sum_loss = 0.0\n",
    "        sum_correct = 0\n",
    "        sum_total = 0\n",
    "        #テスト\n",
    "        for (inputs, labels) in testloader:\n",
    "            #inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            sum_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)  #出力の最大値の添え字を取得\n",
    "            sum_total += labels.size(0)  #labelの数を足していくことでデータの総和を得る\n",
    "            sum_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        mean_loss = sum_loss*BATCH_SIZE/len(trainloader.dataset)\n",
    "        mean_accuracy = float(sum_correct/sum_total)\n",
    "        print(\"test mean loss={}, accuracy={}\".format(mean_loss, mean_accuracy))\n",
    "        test_loss_value.append(mean_loss)\n",
    "        test_acc_value.append(mean_accuracy)\n",
    "        \"\"\"\n",
    "    \n",
    "    #GPUで保存\n",
    "    if torch.cuda.is_available():\n",
    "        model_path = 'model/model_' + target + '.pth'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    #CPUで保存\n",
    "    else:\n",
    "        model_path = 'model/model_cpu_' + target + '.pth'\n",
    "        torch.save(model.to('cpu').state_dict(), model_path)\n",
    "    \"\"\"\n",
    "    #学習ごとのlossの変化を表示\n",
    "    plt.figure(figsize=(6,6))\n",
    "    \n",
    "    plt.plot(range(EPOCH), train_loss_value)\n",
    "    #plt.plot(range(EPOCH), test_loss_value, c='#00ff00')\n",
    "    plt.xlim(0, EPOCH)\n",
    "    plt.ylim(0, 2.5)\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('LOSS')\n",
    "    plt.legend(['train loss', 'test loss'])\n",
    "    plt.title('loss')\n",
    "    \n",
    "    #学習ごとのaccuracyの変化を表示\n",
    "    plt.plot(range(EPOCH), train_acc_value)\n",
    "    #plt.plot(range(EPOCH), test_acc_value, c='#00ff00')\n",
    "    plt.xlim(0, EPOCH)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('ACCURACY')\n",
    "    plt.legend(['train acc', 'test acc'])\n",
    "    plt.title('accuracy')\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UzKU-t3Gwwgg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzKU-t3Gwwgg",
    "outputId": "4b668995-64d4-4fbe-9eea-ea613822692b"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN1d_E01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
