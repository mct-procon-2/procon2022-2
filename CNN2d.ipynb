{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e5737f-488b-47e0-9670-2dd0511b6d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import write\n",
    "import soundfile as sf\n",
    "import random\n",
    "import os, sys\n",
    "import time\n",
    "#import subprocess\n",
    "#subprocess.run(\"pip install pydub\", shell = True)\n",
    "import pydub\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379fa3fc-8957-4b3f-a617-9671726cac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#適宜変える\n",
    "#mainpath = '/content/drive/MyDrive/procon2022/'\n",
    "mainpath = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68309404-c984-4dc3-92b2-e74f022c3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題作成ツール\n",
    "# 無音wavファイル: http://hitotose-switch.blogspot.com/2013/12/wav.html\n",
    "class Question:\n",
    "    SR = 48000 # サンプリング周波数\n",
    "    \n",
    "    # サンプリング値を秒に変換\n",
    "    # こちらはサンプリング値でずらしたいが、Pydubは秒を欲しがる\n",
    "    def rate2sec(rate):\n",
    "        return rate / Question.SR\n",
    "    \n",
    "    # カット 頭と末尾のデータを刈り取る\n",
    "    # 頭と末尾何秒「切り取るか?」を指定\n",
    "    def cut_wave(x, head=0, tail=0):\n",
    "        x = x[head:len(x)-tail]\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    # 2つの波形を合成する(ループで呼び出して複数まぜる、全ての波形を合成)\n",
    "    # カットをしてからここを呼び出す\n",
    "    def mix_wave(mix, x, skip=0):\n",
    "        mix = mix + np.pad(x, [skip, len(mix) - len(x) - skip])\n",
    "        return mix\n",
    "    \n",
    "    # 32個の問題データを作る\n",
    "    # \"wave_file/\"ディレクトリに作成します。ディレクトリを作っておいてください。\n",
    "    # \"muon_10.sec.wav\"はカレントディレクトリに\n",
    "    # サンプルデータは\"JKspeech/\"から引っ張ります\n",
    "    def create(sellect): # sellect: E01、E02にするように \n",
    "        for lp in range(0, 32):\n",
    "            #print(lp)\n",
    "            #print(sellect)\n",
    "            # 無音データ(重ね合わせ用)\n",
    "            muon = AudioSegment.from_file(mainpath + \"muon_10sec.wav\", format=\"wav\")\n",
    "            muon = muon + muon + muon; #30秒の無音データ\n",
    "            # 作成\n",
    "            speech = np.empty(0) # 読みデータ\n",
    "            offset = np.empty(0) # 開始位置\n",
    "            mix = np.array(muon.get_array_of_samples())\n",
    "            max_time = 0\n",
    "            num = random.randint(2, 20)\n",
    "            remain = np.empty(0)\n",
    "            ej = [\"E\", \"J\"]\n",
    "            for i in range(1, 45):\n",
    "                remain = np.append(remain, str(i).zfill(2))\n",
    "            \n",
    "            #print(\"合成数: \" + str(num))\n",
    "            for i in range(0, num):\n",
    "                r_mus = random.randint(0, remain.size - 1)\n",
    "                r_ej = random.randint(0, 1)\n",
    "\n",
    "                # はじめ半分はsellectを含む\n",
    "                if i == num-1 and sellect != \"\" and lp < 16:\n",
    "                    r_ej = 0 if sellect[0] == \"E\" else 1\n",
    "                    r_mus = int(sellect[1:]) - 1\n",
    "                \n",
    "                \n",
    "                # うしろ半分はsellectを含まない\n",
    "                if lp >= 16 and remain[r_mus] == sellect[1:]:\n",
    "                    r_ej = 1 if sellect[0] == \"E\" else 0 # sellectにない言語にする\n",
    "                \n",
    "                \n",
    "                #path = \"/content/drive/MyDrive/procon2022/JKspeech/\" + ej[r_ej] + remain[r_mus] + \".wav\" #勝手に変えました(content/drive)\n",
    "                path = mainpath + \"JKspeech/\" + ej[r_ej] + remain[r_mus] + \".wav\"\n",
    "                speech = np.append(speech, ej[r_ej] + remain[r_mus])\n",
    "                #print(path)\n",
    "                base_sound_AS = AudioSegment.from_file(path, format=\"wav\")\n",
    "                base_sound = np.array(base_sound_AS.get_array_of_samples())\n",
    "                #print(\"初期状態:\" + str(base_sound.duration_seconds) + \"秒\") # カット前の秒数\n",
    "                head_cut = random.randint(0, int(len(base_sound) - 48000)) # 1s以上確実に残して頭からカット\n",
    "                tail_cut = random.randint(0, int(len(base_sound) - head_cut - 48000)) # 1s以上確実に残して後ろからカット\n",
    "                base_sound = Question.cut_wave(base_sound, head = head_cut, tail = tail_cut)\n",
    "                #print(\"最終状態:\" + str(base_sound.duration_seconds) + \"秒\") # カット後の秒数\n",
    "                skip_time = random.randint(0, max_time) #飛ばす時間\n",
    "                offset = np.append(offset, skip_time)\n",
    "                #print(\"スキップ時間:\" + str(Question.rate2sec(skip_time)) + \"秒\")\n",
    "                #max_time = max(max_time, skip_time + int(base_sound.duration_seconds * Question.SR))\n",
    "                max_time = min(max(max_time, skip_time + len(base_sound)), 432000)\n",
    "                #print(\"合計時間:\" + str(Question.rate2sec(max_time)) + \"秒/48000\")\n",
    "                #mix = Question.mix_wave(mix, base_sound, skip=skip_time) # 周波数単位でずらす\n",
    "                mix = Question.mix_wave(mix, base_sound, skip=skip_time) # 周波数単位でずらす\n",
    "                remain = np.delete(remain, r_mus)\n",
    "            \n",
    "            outfile_name = mainpath + \"wave_file/information\" + str(lp) + \".txt\"\n",
    "            f = open(outfile_name, mode='w')\n",
    "            f.write(\"nspeech: \" + str(num) + \"\\n\")\n",
    "            \n",
    "            s = \"speech: \"\n",
    "            for i in range(0, num):\n",
    "                s += str(speech[i])\n",
    "                if (i != num - 1):\n",
    "                    s += \", \"\n",
    "            f.write(s)\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            s = \"offset: \"\n",
    "            for i in range(0, num):\n",
    "                s += str(int(offset[i]))\n",
    "                if (i != num - 1):\n",
    "                    s += \", \"\n",
    "            f.write(s)\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            f.close()\n",
    "            \n",
    "            #print(\"最終時間\" + str(Question.rate2sec(max_time)) + \"秒\")\n",
    "            #mix = mix[:int(Question.rate2sec(max_time) * 1000)]\n",
    "            mix = mix[:min(max_time, 480000)]\n",
    "            outfile_name = mainpath + \"wave_file/mix\" + str(lp) + \".wav\"\n",
    "            mix = AudioSegment(\n",
    "                    mix.astype(\"int16\").tobytes(), \n",
    "                    sample_width=base_sound_AS.sample_width, \n",
    "                    frame_rate=base_sound_AS.frame_rate, \n",
    "                    channels=base_sound_AS.channels,\n",
    "                    )\n",
    "            mix.export(outfile_name, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02200b-1d8b-4aa4-a0bb-2dd7aff6c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50()\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.fc = nn.Linear(in_features=2048, out_features=2, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c60bd15-7a1e-4053-af98-6a73c2d678c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f5f91-3e2b-4a4c-b4eb-387aed0a400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e13bb-f833-4ef4-a41f-210a55a7fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Target = [] # E01からJ44を作成\n",
    "EJ = [\"E\", \"J\"]\n",
    "for ej in EJ:\n",
    "    for i in range(1, 45):\n",
    "        Target.append(ej + str(i).zfill(2))\n",
    "\n",
    "for target in Target:\n",
    "    #GPUで保存\n",
    "    if torch.cuda.is_available():\n",
    "        model_path = mainpath + 'model/model_cuda_' + target + '.pth'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    #CPUで保存\n",
    "    else:\n",
    "        model_path = mainpath + 'model/model_cpu_' + target + '.pth'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec5cb2-da80-43e3-bc52-0fc74ded7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習に使うメソッド\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85226422-7c38-4112-bb37-81c8e4f13b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9948cc-0be9-48e6-a595-766155b5b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = [] # E01からJ44を作成\n",
    "EJ = [\"E\", \"J\"]\n",
    "for ej in EJ:\n",
    "    for i in range(1, 45):\n",
    "        Target.append(ej + str(i).zfill(2))\n",
    "\n",
    "\n",
    "#学習\n",
    "for learntimes in range(0, 500):\n",
    "    print()\n",
    "    print(learntimes)\n",
    "    # 問題作成\n",
    "    print(\"make problems...\")\n",
    "    question = Question()\n",
    "    question.create()\n",
    "    print(\"finish\")\n",
    "\n",
    "    #波形データを得る\n",
    "    file_path = mainpath + \"wave_file/\"\n",
    "    wave_name = np.array([\"mix\" + str(i) + \".wav\" for i in range(0, 32)])\n",
    "    #波形の長さが異なるのでどうにかしないといけない\n",
    "    #そのままメルスペクトログラム化する\n",
    "    #メルスペクトログラムの大きさを調節する\n",
    "    X = np.empty(0)\n",
    "    for name in wave_name:\n",
    "        y, sr = librosa.load(mainpath + file_path + name)\n",
    "        hop_length = len(y) // 224\n",
    "        spec_log = librosa.power_to_db(np.abs(librosa.stft(y, n_fft=447, hop_length=hop_length)))\n",
    "        X = np.append(X, spec_log[:224,:224])\n",
    "    X = np.reshape(X, (-1,224,224))\n",
    "    #print(X.shape)\n",
    "\n",
    "    for target in Target:\n",
    "        print(target, end = ' ')\n",
    "        #モデルの読み込み\n",
    "        #モデルを一度保存してないとエラーします（とりあえずはここのコード無視してね）\n",
    "        #GPU\n",
    "        if torch.cuda.is_available():\n",
    "            model_path = mainpath + 'model/cnn_cuda_2d' + target + '.pth'\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "        #CPU\n",
    "        else:\n",
    "            model_path = mainpath + 'model/cnn_cpu_2d' + target + '.pth'\n",
    "            model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "        #狙いの音声が使われているかを取る\n",
    "        file_path = mainpath + \"wave_file/\"\n",
    "        label_name = np.array([\"information\" + str(i) + \".txt\" for i in range(0,32)])\n",
    "\n",
    "        Y = np.empty(0)\n",
    "        for name in label_name:\n",
    "            f = open(file_path + name, 'r')\n",
    "            s = f.read()\n",
    "            #答えは[無い率,有る率]とする\n",
    "            if target in s:\n",
    "                Y = np.append(Y, 1)\n",
    "            else:\n",
    "                Y = np.append(Y, 0)\n",
    "\n",
    "        #データセット作成\n",
    "        #参考：https://dreamer-uma.com/pytorch-dataset/\n",
    "        tensorX = torch.tensor(X, dtype=torch.float32)\n",
    "        tensorY = torch.tensor(Y, dtype=torch.int64)\n",
    "        Dataset = torch.utils.data.TensorDataset(tensorX, tensorY)\n",
    "\n",
    "        #データローダー作成\n",
    "        trainloader = torch.utils.data.DataLoader(dataset=Dataset,\n",
    "                                                batch_size = 32,\n",
    "                                                shuffle = True,\n",
    "                                                num_workers = 0)\n",
    "\n",
    "        #学習\n",
    "        #参考 https://qiita.com/mathlive/items/8e1f9a8467fff8dfd03c\n",
    "        train_loss_value = []\n",
    "        train_acc_value = []\n",
    "\n",
    "        BATCH_SIZE = 32\n",
    "        EPOCH = 1\n",
    "        for epoch in range(EPOCH):\n",
    "            print(\"epoch:\" + str(epoch))\n",
    "            sum_loss = 0.0\n",
    "            sum_correct = 0\n",
    "            sum_total = 0\n",
    "            for (inputs, labels) in trainloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                #inputsの大きさが24000(0.5秒)じゃないとダメ\n",
    "                inputs = inputs.unsqueeze(1)\n",
    "                #print(inputs.shape)\n",
    "                outputs = model(inputs)\n",
    "                #結果出力\n",
    "                sof = nn.Softmax(dim=1)(outputs)\n",
    "                print(sof[0])\n",
    "                print(labels[0])\n",
    "                #\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                sum_loss += loss.item()\n",
    "\n",
    "            clear_output(True)\n",
    "            mean_loss = sum_loss*BATCH_SIZE/len(trainloader.dataset)\n",
    "            print(\"train mean loss={}\".format(mean_loss))\n",
    "            train_loss_value.append(mean_loss)\n",
    "\n",
    "        time.sleep(0.1)\n",
    "        #GPUで保存\n",
    "        if torch.cuda.is_available():\n",
    "            model_path = mainpath + 'model/cnn_cuda_2d' + target + '.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        #CPUで保存\n",
    "        else:\n",
    "            model_path = mainpath + 'model/cnn_cpu_2d' + target + '.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d7b07-adeb-474a-927a-c925e6127d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
