{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46667c2c-c168-4e03-aefc-2227f57ce9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import write\n",
    "import soundfile as sf\n",
    "import random\n",
    "import os, sys\n",
    "import time\n",
    "#import subprocess\n",
    "#subprocess.run(\"pip install pydub\", shell = True)\n",
    "import pydub\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba031e8-8124-40ef-a5ce-290b880fe431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#適宜変える\n",
    "#mainpath = '/content/drive/MyDrive/procon2022/'\n",
    "mainpath = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54bf99-0708-49ab-aad4-a11a074ad07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題作成ツール\n",
    "# 無音wavファイル: http://hitotose-switch.blogspot.com/2013/12/wav.html\n",
    "class Question:\n",
    "    SR = 48000 # サンプリング周波数\n",
    "    \n",
    "    # サンプリング値を秒に変換\n",
    "    # こちらはサンプリング値でずらしたいが、Pydubは秒を欲しがる\n",
    "    def rate2sec(rate):\n",
    "        return rate / Question.SR\n",
    "    \n",
    "    # カット 頭と末尾のデータを刈り取る\n",
    "    # 頭と末尾何秒「切り取るか?」を指定\n",
    "    def cut_wave(x, head=0, tail=0):\n",
    "        x = x[head:len(x)-tail]\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    # 2つの波形を合成する(ループで呼び出して複数まぜる、全ての波形を合成)\n",
    "    # カットをしてからここを呼び出す\n",
    "    def mix_wave(mix, x, skip=0):\n",
    "        mix = mix + np.pad(x, [skip, len(mix) - len(x) - skip])\n",
    "        return mix\n",
    "    \n",
    "    # 32個の問題データを作る\n",
    "    # \"wave_file/\"ディレクトリに作成します。ディレクトリを作っておいてください。\n",
    "    # \"muon_10.sec.wav\"はカレントディレクトリに\n",
    "    # サンプルデータは\"JKspeech/\"から引っ張ります\n",
    "    def create(sellect): # sellect: E01、E02にするように \n",
    "        for lp in range(0, 32):\n",
    "            #print(lp)\n",
    "            #print(sellect)\n",
    "            # 無音データ(重ね合わせ用)\n",
    "            muon = AudioSegment.from_file(mainpath + \"muon_10sec.wav\", format=\"wav\")\n",
    "            muon = muon + muon + muon; #30秒の無音データ\n",
    "            # 作成\n",
    "            speech = np.empty(0) # 読みデータ\n",
    "            offset = np.empty(0) # 開始位置\n",
    "            mix = np.array(muon.get_array_of_samples())\n",
    "            max_time = 0\n",
    "            num = random.randint(2, 20)\n",
    "            remain = np.empty(0)\n",
    "            ej = [\"E\", \"J\"]\n",
    "            for i in range(1, 45):\n",
    "                remain = np.append(remain, str(i).zfill(2))\n",
    "            \n",
    "            #print(\"合成数: \" + str(num))\n",
    "            for i in range(0, num):\n",
    "                r_mus = random.randint(0, remain.size - 1)\n",
    "                r_ej = random.randint(0, 1)\n",
    "\n",
    "                # はじめ半分はsellectを含む\n",
    "                if i == num-1 and sellect != \"\" and lp < 16:\n",
    "                    r_ej = 0 if sellect[0] == \"E\" else 1\n",
    "                    r_mus = int(sellect[1:]) - 1\n",
    "                \n",
    "                \n",
    "                # うしろ半分はsellectを含まない\n",
    "                if lp >= 16 and remain[r_mus] == sellect[1:]:\n",
    "                    r_ej = 1 if sellect[0] == \"E\" else 0 # sellectにない言語にする\n",
    "                \n",
    "                \n",
    "                #path = \"/content/drive/MyDrive/procon2022/JKspeech/\" + ej[r_ej] + remain[r_mus] + \".wav\" #勝手に変えました(content/drive)\n",
    "                path = mainpath + \"JKspeech/\" + ej[r_ej] + remain[r_mus] + \".wav\"\n",
    "                speech = np.append(speech, ej[r_ej] + remain[r_mus])\n",
    "                #print(path)\n",
    "                base_sound_AS = AudioSegment.from_file(path, format=\"wav\")\n",
    "                base_sound = np.array(base_sound_AS.get_array_of_samples())\n",
    "                #print(\"初期状態:\" + str(base_sound.duration_seconds) + \"秒\") # カット前の秒数\n",
    "                head_cut = random.randint(0, int(len(base_sound) - 48000)) # 1s以上確実に残して頭からカット\n",
    "                tail_cut = random.randint(0, int(len(base_sound) - head_cut - 48000)) # 1s以上確実に残して後ろからカット\n",
    "                base_sound = Question.cut_wave(base_sound, head = head_cut, tail = tail_cut)\n",
    "                #print(\"最終状態:\" + str(base_sound.duration_seconds) + \"秒\") # カット後の秒数\n",
    "                skip_time = random.randint(0, max_time) #飛ばす時間\n",
    "                offset = np.append(offset, skip_time)\n",
    "                #print(\"スキップ時間:\" + str(Question.rate2sec(skip_time)) + \"秒\")\n",
    "                #max_time = max(max_time, skip_time + int(base_sound.duration_seconds * Question.SR))\n",
    "                max_time = min(max(max_time, skip_time + len(base_sound)), 432000)\n",
    "                #print(\"合計時間:\" + str(Question.rate2sec(max_time)) + \"秒/48000\")\n",
    "                #mix = Question.mix_wave(mix, base_sound, skip=skip_time) # 周波数単位でずらす\n",
    "                mix = Question.mix_wave(mix, base_sound, skip=skip_time) # 周波数単位でずらす\n",
    "                remain = np.delete(remain, r_mus)\n",
    "            \n",
    "            outfile_name = mainpath + \"wave_file/information\" + str(lp) + \".txt\"\n",
    "            f = open(outfile_name, mode='w')\n",
    "            f.write(\"nspeech: \" + str(num) + \"\\n\")\n",
    "            \n",
    "            s = \"speech: \"\n",
    "            for i in range(0, num):\n",
    "                s += str(speech[i])\n",
    "                if (i != num - 1):\n",
    "                    s += \", \"\n",
    "            f.write(s)\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            s = \"offset: \"\n",
    "            for i in range(0, num):\n",
    "                s += str(int(offset[i]))\n",
    "                if (i != num - 1):\n",
    "                    s += \", \"\n",
    "            f.write(s)\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            f.close()\n",
    "            \n",
    "            #print(\"最終時間\" + str(Question.rate2sec(max_time)) + \"秒\")\n",
    "            #mix = mix[:int(Question.rate2sec(max_time) * 1000)]\n",
    "            mix = mix[:min(max_time, 480000)]\n",
    "            outfile_name = mainpath + \"wave_file/mix\" + str(lp) + \".wav\"\n",
    "            mix = AudioSegment(\n",
    "                    mix.astype(\"int16\").tobytes(), \n",
    "                    sample_width=base_sound_AS.sample_width, \n",
    "                    frame_rate=base_sound_AS.frame_rate, \n",
    "                    channels=base_sound_AS.channels,\n",
    "                    )\n",
    "            mix.export(outfile_name, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbff05-32ce-40bf-9ec8-618d5a611bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://lotti.info/mnist-dence-cnn-rnn-lstm/#RNN\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        self.seq_len = 200\n",
    "        self.feature_size = 2400\n",
    "        self.hidden_layer_size = 4096   # 隠れ層のサイズ\n",
    "        self.lstm_layers = 1           # LSTMのレイヤー数　(LSTMを何層重ねるか)\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.feature_size, \n",
    "                            self.hidden_layer_size, \n",
    "                            num_layers = self.lstm_layers)\n",
    "        \n",
    "        self.fc = nn.Linear(self.hidden_layer_size, 2)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "    def init_hidden_cell(self, batch_size, device): # LSTMの隠れ層 hidden と記憶セル cell を初期化\n",
    "        hedden = torch.zeros(self.lstm_layers, batch_size, self.hidden_layer_size).to(device)\n",
    "        cell = torch.zeros(self.lstm_layers, batch_size, self.hidden_layer_size).to(device)\n",
    "        return (hedden, cell)\n",
    "\n",
    "    def forward(self, x, device):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        self.hidden_cell = self.init_hidden_cell(batch_size, device)\n",
    "        \n",
    "        x = x.view(batch_size, self.seq_len, self.feature_size)  # (Batch, Cannel, Height, Width) -> (Batch, Height, Width) = (Batch, Seqence, Feature)\n",
    "                                                                 # 画像の Height を時系列のSequenceに、Width を特徴量の次元としてLSTMに入力する\n",
    "        x = x.permute(1, 0, 2)                                   # (Batch, Seqence, Feature) -> (Seqence , Batch, Feature)\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm(x, self.hidden_cell)    # LSTMの入力データのShapeは(Seqence, Batch, Feature)\n",
    "                                                                 # (h_n) のShapeは (num_layers, batch, hidden_size)\n",
    "        x = h_n[-1,:,:]                                          # lstm_layersの最後のレイヤーを取り出す  (B, h)\n",
    "        x = self.fc(x)\n",
    "        #x = self.soft(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b42d1-ac52-4ee4-8ea3-f3340cbb9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b6a92e-574a-46fa-a63a-8ca9d1e9e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = [] # E01からJ44を作成\n",
    "EJ = [\"E\", \"J\"]\n",
    "for ej in EJ:\n",
    "    for i in range(1, 45):\n",
    "        Target.append(ej + str(i).zfill(2))\n",
    "\n",
    "for target in Target:\n",
    "    #GPUで保存\n",
    "    if torch.cuda.is_available():\n",
    "        model_path = mainpath + 'model/RNN_cuda_1d' + target + '.pth'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    #CPUで保存\n",
    "    else:\n",
    "        model_path = mainpath + 'model/RNN_cpu_1d' + target + '.pth'\n",
    "        torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de897e8c-a92c-4472-8d68-42b940b0311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習に使うメソッド\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1144e-381d-4f35-b744-d28e5320be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d664b800-3309-41ff-8be5-d07fb1cab550",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = [] # E01からJ44を作成\n",
    "EJ = [\"E\", \"J\"]\n",
    "for ej in EJ:\n",
    "    for i in range(1, 45):\n",
    "        Target.append(ej + str(i).zfill(2))\n",
    "\n",
    "for target in Target:\n",
    "    \n",
    "    #testloaderをつくる\n",
    "    question = Question\n",
    "    question.create(target)\n",
    "    #波形データを得る\n",
    "    file_path = mainpath + \"test_wave_file/\"\n",
    "    wave_name = np.array([\"mix\" + str(i) + \".wav\" for i in range(0, 32)])\n",
    "    #波形の長さが異なるのでどうにかしないといけない\n",
    "    X = np.empty(0)\n",
    "    FS = np.empty(0)\n",
    "    for name in wave_name:\n",
    "        x, fs = librosa.load(file_path + name, sr=48000)\n",
    "        if len(x) > 480000:\n",
    "            x = x[0:480000]\n",
    "        else:\n",
    "            x = np.pad(x, [0, 480000-len(x)])\n",
    "        X = np.append(X, x)\n",
    "        #FS = np.append(FS, fs)\n",
    "    X = X.reshape([-1,480000])\n",
    "\n",
    "    #狙いの音声が使われているかを取る\n",
    "    label_name = np.array([\"information\" + str(i) + \".txt\" for i in range(0,32)])\n",
    "\n",
    "    Y = np.empty(0)\n",
    "    for name in label_name:\n",
    "        f = open(file_path + name, 'r')\n",
    "        s = f.read()\n",
    "        if target in s:\n",
    "            Y = np.append(Y, 1)\n",
    "        else:\n",
    "            Y = np.append(Y, 0)\n",
    "\n",
    "    #データセット作成\n",
    "    #参考：https://dreamer-uma.com/pytorch-dataset/\n",
    "    tensorX = torch.tensor(X, dtype=torch.float32)\n",
    "    tensorY = torch.tensor(Y, dtype=torch.int64)\n",
    "    Dataset = torch.utils.data.TensorDataset(tensorX, tensorY)\n",
    "\n",
    "    #データローダー作成\n",
    "    testloader = torch.utils.data.DataLoader(dataset=Dataset,\n",
    "                                            batch_size = 32,\n",
    "                                            shuffle = False,\n",
    "                                            num_workers = 0)\n",
    "    \n",
    "    #validloarderをつくる\n",
    "    question = Question\n",
    "    question.create(target)\n",
    "    #波形データを得る\n",
    "    file_path = mainpath + \"valid_wave_file/\"\n",
    "    wave_name = np.array([\"mix\" + str(i) + \".wav\" for i in range(0, 32)])\n",
    "    #波形の長さが異なるのでどうにかしないといけない\n",
    "    X = np.empty(0)\n",
    "    for name in wave_name:\n",
    "        x, fs = librosa.load(file_path + name, sr=48000)\n",
    "        if len(x) > 480000:\n",
    "            x = x[0:480000]\n",
    "        else:\n",
    "            x = np.pad(x, [0, 480000-len(x)])\n",
    "        X = np.append(X, x)\n",
    "    X = X.reshape([-1,480000])\n",
    "\n",
    "    #狙いの音声が使われているかを取る\n",
    "    label_name = np.array([\"information\" + str(i) + \".txt\" for i in range(0,32)])\n",
    "    \n",
    "    Y = np.empty(0)\n",
    "    for name in label_name:\n",
    "        f = open(file_path + name, 'r')\n",
    "        s = f.read()\n",
    "        if target in s:\n",
    "            Y = np.append(Y, 1)\n",
    "        else:\n",
    "            Y = np.append(Y, 0)\n",
    "    \n",
    "    #データセット作成\n",
    "    #参考：https://dreamer-uma.com/pytorch-dataset/\n",
    "    tensorX = torch.tensor(X, dtype=torch.float32)\n",
    "    tensorY = torch.tensor(Y, dtype=torch.int64)\n",
    "    Dataset = torch.utils.data.TensorDataset(tensorX, tensorY)\n",
    "    \n",
    "    #データローダー作成\n",
    "    validloader = torch.utils.data.DataLoader(dataset=Dataset,\n",
    "                                            batch_size = 32,\n",
    "                                            shuffle = False,\n",
    "                                            num_workers = 0)\n",
    "    \n",
    "    #モデルの読み込み\n",
    "    #モデルを一度保存してないとエラーします（とりあえずはここのコード無視してね）\n",
    "    #GPU\n",
    "    if torch.cuda.is_available():\n",
    "        model_path = mainpath + 'model/RNN_cuda_1d' + target + '.pth'\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "    #CPU\n",
    "    else:\n",
    "        model_path = mainpath + 'model/RNN_cpu_1d' + target +'.pth'\n",
    "        model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "    #学習\n",
    "    train_loss_value = []\n",
    "    test_loss_value = []\n",
    "    valid_loss_value = []\n",
    "    for learntimes in range(1, 500):\n",
    "        print()\n",
    "        print(learntimes)\n",
    "        # 問題作成\n",
    "        print(\"make problems...\")\n",
    "        question = Question\n",
    "        question.create(target)\n",
    "        print(\"finish\")\n",
    "\n",
    "        #波形データを得る\n",
    "        file_path = mainpath + \"wave_file/\"\n",
    "        wave_name = np.array([\"mix\" + str(i) + \".wav\" for i in range(0, 32)])\n",
    "        #波形の長さが異なるのでどうにかしないといけない\n",
    "        X = np.empty(0)\n",
    "        FS = np.empty(0)\n",
    "        for name in wave_name:\n",
    "            x, fs = librosa.load(file_path + name, sr=48000)\n",
    "            if len(x) > 480000:\n",
    "                x = x[0:480000]\n",
    "            else:\n",
    "                x = np.pad(x, [0, 480000-len(x)])\n",
    "            X = np.append(X, x)\n",
    "            #FS = np.append(FS, fs)\n",
    "        X = X.reshape([-1,480000])\n",
    "\n",
    "        #狙いの音声が使われているかを取る\n",
    "        file_path = mainpath + \"wave_file/\"\n",
    "        label_name = np.array([\"information\" + str(i) + \".txt\" for i in range(0,32)])\n",
    "\n",
    "        Y = np.empty(0)\n",
    "        for name in label_name:\n",
    "            f = open(file_path + name, 'r')\n",
    "            s = f.read()\n",
    "            if target in s:\n",
    "                Y = np.append(Y, 1)\n",
    "            else:\n",
    "                Y = np.append(Y, 0)\n",
    "\n",
    "        #データセット作成\n",
    "        #参考：https://dreamer-uma.com/pytorch-dataset/\n",
    "        tensorX = torch.tensor(X, dtype=torch.float32)\n",
    "        tensorY = torch.tensor(Y, dtype=torch.int64)\n",
    "        Dataset = torch.utils.data.TensorDataset(tensorX, tensorY)\n",
    "\n",
    "        #データローダー作成\n",
    "        trainloader = torch.utils.data.DataLoader(dataset=Dataset,\n",
    "                                                batch_size = 32,\n",
    "                                                shuffle = True,\n",
    "                                                num_workers = 0)\n",
    "\n",
    "        #学習\n",
    "        #参考 https://qiita.com/mathlive/items/8e1f9a8467fff8dfd03c\n",
    "\n",
    "        clear_output(True)\n",
    "        \"\"\"\n",
    "        if learntimes % 50 == 1 :\n",
    "            EPOCH = 10\n",
    "            BATCH_SIZE = 32\n",
    "            for epoch in range(EPOCH):\n",
    "                sum_loss = 0.0\n",
    "                for (inputs, labels) in validloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    inputs = inputs.unsqueeze(1)\n",
    "                    outputs = model(inputs, device)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    sum_loss += loss.item()\n",
    "\n",
    "                mean_loss = sum_loss*BATCH_SIZE/len(trainloader.dataset)\n",
    "                print(\"valid mean loss={}\".format(mean_loss))\n",
    "        \"\"\"\n",
    "\n",
    "        BATCH_SIZE = 32\n",
    "        EPOCH = 3\n",
    "        for epoch in range(EPOCH):\n",
    "            print(\"epoch:\" + str(epoch))\n",
    "            sum_loss = 0.0\n",
    "            for (inputs, labels) in trainloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                inputs = inputs.unsqueeze(1)\n",
    "                outputs = model(inputs, device)\n",
    "                #結果出力\n",
    "                #sof = nn.Softmax(dim=1)(outputs)\n",
    "                print(outputs[0])\n",
    "                print(labels[0])\n",
    "                #\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                sum_loss += loss.item()\n",
    "\n",
    "            mean_loss = sum_loss*BATCH_SIZE/len(trainloader.dataset)\n",
    "            print(\"train mean loss={}\".format(mean_loss))\n",
    "            train_loss_value.append(mean_loss)\n",
    "\n",
    "            BATCH_SIZE = 32\n",
    "            sum_loss = 0.0\n",
    "            for (inputs, labels) in testloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                inputs = inputs.unsqueeze(1)\n",
    "                outputs = model(inputs, device)\n",
    "                print(outputs[0])\n",
    "                print(labels[0])\n",
    "                loss = criterion(outputs, labels)\n",
    "                sum_loss += loss.item()\n",
    "            mean_loss = sum_loss*BATCH_SIZE/len(testloader.dataset)\n",
    "            print(\"test mean loss={}\".format(mean_loss))\n",
    "            test_loss_value.append(mean_loss)\n",
    "\n",
    "            BATCH_SIZE = 32\n",
    "            sum_loss = 0.0\n",
    "            for (inputs, labels) in validloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                inputs = inputs.unsqueeze(1)\n",
    "                outputs = model(inputs, device)\n",
    "                #結果出力\n",
    "                #print(nn.Softmax(dim=1)(outputs)[0])\n",
    "                print(outputs[0])\n",
    "                print(labels[0])\n",
    "                #\n",
    "                loss = criterion(outputs, labels)\n",
    "                optimizer.step()\n",
    "                sum_loss += loss.item()\n",
    "\n",
    "            mean_loss = sum_loss*BATCH_SIZE/len(trainloader.dataset)\n",
    "            print(\"valid mean loss={}\".format(mean_loss))\n",
    "            valid_loss_value.append(mean_loss)\n",
    "\n",
    "        plt.plot(range(EPOCH * learntimes), train_loss_value)\n",
    "        plt.plot(range(EPOCH * learntimes), test_loss_value, c='#00ff00')\n",
    "        plt.plot(range(EPOCH * learntimes), valid_loss_value, c='#ff0000')\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "\n",
    "        time.sleep(0.1)\n",
    "        #GPUで保存\n",
    "        if torch.cuda.is_available():\n",
    "            model_path = mainpath + 'model/RNN_cuda_1d' + target + '.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        #CPUで保存\n",
    "        else:\n",
    "            model_path = mainpath + 'model/RNN_cpu_1d' + target + '.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25985a-e964-4a92-96c7-bb952c403e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
